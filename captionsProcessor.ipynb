{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from configData import configVars\n",
    "\n",
    "config = configVars()\n",
    "# The video name can be set manually as well post initialization to use the same config values for different videos.\n",
    "# config.videoToUse = \"Sakai\"\n",
    "config.setFromEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transcriptLoader import retrieveTranscript\n",
    "from questionGenerator import retrieveQuestions\n",
    "\n",
    "videoData = retrieveTranscript(config)\n",
    "questionData = retrieveQuestions(config, videoData=videoData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional code for Evaluation of Questions\n",
    "\n",
    "The following code block is for generating an Excel file of the questions to be used for evaluating the generated questions. \n",
    "This is still not in a complete state, and is currently for protyping and testing only. \n",
    "\n",
    "You will need to install `tqdm`, `xlsxwriter` and possibly `openpyxl` Python packages via pip for the code to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "\n",
    "!pip install tqdm\n",
    "!pip install xlsxwriter\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from configData import configVars, captionsFolder, outputFolder\n",
    "from topicExtractor import retrieveTopics\n",
    "from transcriptLoader import retrieveTranscript\n",
    "from questionGenerator import retrieveQuestions\n",
    "from questionGenerator import processCaptions\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from pandas.io.formats import excel\n",
    "excel.ExcelFormatter.header_style = None\n",
    "\n",
    "# This list is a list of videos present in the Captions folder for which the questions are to be generated.\n",
    "# To generate questions for all videos in the Captions folder, set fileList = os.listdir(captionsFolder)\n",
    "fileList = [\n",
    "    \"IMSE 514 Presentation\",\n",
    "    \"Kalpana-GenAI-Das\",\n",
    "    \"Kalpana-maizey2-das\",\n",
    "    \"Kalpana-U-M MaizeyDas\",\n",
    "    \"New Google Assignments in Canvas\",\n",
    "    \"New Quizzes - Basics\",\n",
    "    \"New Quizzes Video\",\n",
    "    \"Piazza Introduction Workshop\",\n",
    "    # \"Rearrange Playlist video\",\n",
    "    \"Sakai\",\n",
    "]\n",
    "\n",
    "# This is hardcoded, based on the known column it would be assigned to in the Excel file.\n",
    "# I did not try to make this dynamic as it is a one-time use case.\n",
    "wrappedCols  = {'Question': 'C', 'Answers':'G', 'Reason':'I'}\n",
    "\n",
    "def makeExcelComparer(DFData, fileName, transcript):\n",
    "    \"\"\"\n",
    "    Generate an Excel file with questions analysis based on the provided data.\n",
    "\n",
    "    Args:\n",
    "        DFData (pandas.DataFrame): DataFrame containing the data for analysis.\n",
    "        fileName (str): Name of the file being analyzed.\n",
    "        transcript (pandas.DataFrame): DataFrame containing the transcript data.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the path to save the Excel file.\n",
    "    dfSavePath = os.path.join(\n",
    "            outputFolder,\n",
    "            fileName,\n",
    "            f\"Questions Analysis - {fileName}.xlsx\",\n",
    "        )\n",
    "    \n",
    "    # Automated this process so that the SRT file is copied to the output folder for reference.\n",
    "    # Find the original SRT file\n",
    "    srtFile = glob.glob(\n",
    "            os.path.join(captionsFolder, fileName, \"*.srt\")\n",
    "        )[0]\n",
    "    # Find the path to save the SRT file.\n",
    "    srtCopy = os.path.join(\n",
    "        outputFolder,\n",
    "        fileName,\n",
    "        f\"Transcript - {fileName}.srt\",\n",
    "    )\n",
    "    # Copy the SRT file to the output folder.\n",
    "    shutil.copyfile(srtFile, srtCopy)\n",
    "    \n",
    "    # Merge the two dataframes to get the transcript data for each question.\n",
    "    mergedDF = pd.concat([DFData['LangChain'], DFData['BERTopic']]).reset_index(drop=False)\n",
    "\n",
    "    for index, row in mergedDF.iterrows():\n",
    "        start = datetime.strptime(row['Start'], '%H:%M:%S')\n",
    "        end = datetime.strptime(row['End'], '%H:%M:%S')\n",
    "        transcriptSlice = transcript[(transcript['Start'] >= start) & (transcript['End'] <= end)]\n",
    "        if transcriptSlice.empty:\n",
    "            transcriptSlice = transcript[(transcript['Start'] >= start)].head(1)\n",
    "        relevantText = \" \".join(transcriptSlice['Combined Lines'].tolist())\n",
    "\n",
    "        mergedDF.at[index, 'Transcript'] = relevantText\n",
    "    \n",
    "    # display(mergedDF)\n",
    "\n",
    "    # Write the data to an Excel file.\n",
    "    # This is little janky and is a manual effort to make the Excel file readable.\n",
    "    # It cuts out the need to manually format the Excel file.\n",
    "    with pd.ExcelWriter(dfSavePath, engine=\"xlsxwriter\") as writer:\n",
    "        mergedDF.to_excel(writer, sheet_name=fileName[:31])\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[fileName[:31]]\n",
    "\n",
    "        columns = list(mergedDF.columns)\n",
    "        wrap_format = workbook.add_format({'text_wrap': True})\n",
    "        header_format = workbook.add_format({'bold': True, 'text_wrap': True, 'align': 'center'})\n",
    "        for col in columns:\n",
    "            if col.startswith('Is this question:'):\n",
    "                worksheet.set_column(columns.index(col)+1,columns.index(col)+1, 15, header_format)\n",
    "            else:\n",
    "                worksheet.set_column(columns.index(col)+1,columns.index(col)+1, None, wrap_format)\n",
    "\n",
    "        for col in wrappedCols:\n",
    "            excel_header  =  wrappedCols[col] + ':' + wrappedCols[col]\n",
    "            worksheet.set_column(excel_header, 50, wrap_format)\n",
    "        \n",
    "        worksheet.set_column('M:M', 200, wrap_format)\n",
    "\n",
    "        writer.close()\n",
    "\n",
    "# Run the process for each video in the list.\n",
    "for fileName in tqdm(fileList):\n",
    "\n",
    "    # This dictionary is used to store the data for each generation model for a given video.\n",
    "    DFData = {}\n",
    "    for generationModel in ['LangChain', 'BERTopic']:\n",
    "    \n",
    "        print(f\"Processing {fileName} with {generationModel}...\")\n",
    "        config = configVars()\n",
    "        config.setFromEnv()\n",
    "        config.videoToUse = fileName\n",
    "        config.generationModel = generationModel\n",
    "        if config.generationModel == \"LangChain\":\n",
    "            config.windowSize = 120\n",
    "\n",
    "        videoData = retrieveTranscript(config)\n",
    "\n",
    "        topicModeller = None\n",
    "        if config.generationModel == \"BERTopic\":\n",
    "            print(f\"\\t--> Retrieving Topics for {config.videoToUse}...\")\n",
    "            topicModeller = retrieveTopics(config, videoData)\n",
    "\n",
    "        generatedData = retrieveQuestions(config, videoData=videoData, topicModeller=topicModeller)\n",
    "        DFData[generationModel] = generatedData.makeDF()\n",
    "\n",
    "    # Generate the Excel file for the video.\n",
    "    makeExcelComparer(DFData, fileName, videoData.combinedTranscript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annoto-gai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# Enter your OpenAI key and details here.
# You need to add aditional details when using the UM Azure backend.
OPENAI_API_KEY=''
# OPENAI_API_BASE=''
OPENAI_API_VERSION='2024-02-01'
OPENAI_API_MODEL='gpt-4'
OPENAI_API_ORGANIZATION=''

# This replaces OPENAI_API_BASE, which breaks with LangChain's Azure API functions.
AZURE_OPENAI_ENDPOINT=''

# Specify log level for code. Defaults to DEBUG. Will default to INFO if invalid input is entered.
# Available options: DEBUG, INFO, WARN, ERROR, FATAL
LOG_LEVEL='INFO'

# Specify the path to the parent folder of video you want to use, located inside the 'Captions' folder. 
# The .srt files must be stored within this folder.
VIDEO_TO_USE=''

# Specify the type of question generation model to use.
# Available options: 'BERTopic', 'LangChain'
# Defaults to 'BERTopic'.
GENERATION_MODEL='BERTopic'

# Approximate window size of the captions taken from the .srt file.
# Value must be >= 1, but it is recommended to keep it between 10-30s for BERTopic, and around 2 minutes for LangChain.
# Defaults to 30.
WINDOW_SIZE=30

# Specify the number of questions that will be attempted to be generated for the given video.
# In BERTopic mode, there might not be enough clear context to generate the specified number of questions, 
#   So the actual number of questions generated might be less in certain cases,
#   which will equal the number of relevant regions found useful to generate questions.
#   If set to -1, the number of questions generated will be equal to the number of topics found.
# In LangChain mode, the number of questions generated will be equal to the specified number.
# Defaults to 3 questions generated per video.
QUESTION_COUNT=3

# Toggle for overwriting existing saved transcript if present, to reprocess and extract the transcript.
# 1 for overwriting existing models, 0 for not overwriting existing models.
# Defaults to 0.
OVERWRITE_EXISTING_TRANSCRIPT=0

# Toggle for overwriting existing saved question data if present, to generate new questions.
# NOTE: If you choose to overwrite the existing topic model, this will be automatically set to 1 as well.
# 1 for overwriting existing question data, 0 for not overwriting existing question data.
# Defaults to 0
OVERWRITE_EXISTING_QUESTIONS=0

#-------------------------Parameters For BERTopic only-------------------------#
# The following parameters are only used when the 'BERTopic' mode is selected for question generation.

# Toggle for overwriting existing saved BERTopic models if present, to run a new model.
# NOTE: If you choose to overwrite the existing transcript data, this will be automatically set to 1 as well.
# 1 for overwriting existing models, 0 for not overwriting existing models.
# Defaults to 0.
OVERWRITE_EXISTING_TOPICMODEL=0

# If the duration of a given topic is longer than the context window, 
# The text only from the end of the topic's duration matching the length of the context window 
# Will be used for generating questions.
# If set to 0, all of the data will be used.
# Defaults to 600s for 10 minutes of context. Ideally should be a few minutes long at least for ebough relevent context.
RELEVANT_TEXT_CONTEXT_WINDOW=600

# Specify the prompt for the LangChain model that runs atop the BERTopic model to generate a human-interpretable summary of the topics.
# Defaults to the prompt below. Do not adjust this unless you tuning the outputs for the generated topics.
LANGCHAIN_PROMPT="Give a single label that is only a few words long to summarize what these documents are about."

# Specify the system prompt for question generation using the OpenAI API.
# Defaults to the prompt below. Do not adjust this unless you are tuning the outputs for the generated questions.
QUESTION_PROMPT="You are a question-generating bot that generates questions for a given topic based on the provided relevant trancription text from a video."